{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k9-Z82i495Gl"
   },
   "source": [
    "#       Seq2Seq: Text Summarization with Keras\n",
    "#### ディープラーニングによる文章要約\n",
    "![](http://abigailsee.com/img/pointer-gen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pw_oyfrE95Go"
   },
   "source": [
    "## Process\n",
    "1. Preprocessing\n",
    "2. Word2vec\n",
    "3. Building Seq2Seq Architecture\n",
    "4. Training with  BBC article&summary Dataset\n",
    "5. Generate Summary with my_summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2QnkkQv95Gq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QeKq5tai95Gu"
   },
   "outputs": [],
   "source": [
    "news_category = [\"business\", \"entertainment\", \"politics\", \"sport\", \"tech\"]\n",
    "\n",
    "row_doc = \"/Users/akr712/Desktop/Text_Summarization_using_Keras/Row News Articles/\"\n",
    "summary_doc = \"/Users/akr712/Desktop/Text_Summarization_using_Keras/Summaries/\"\n",
    "\n",
    "data={\"articles\":[], \"summaries\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "682uVCoC95Gy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "directories = {\"news\": row_doc, \"summary\": summary_doc}\n",
    "row_dict = {}\n",
    "sum_dict = {}\n",
    "\n",
    "for path in directories.values():\n",
    "    if path == row_doc:\n",
    "        file_dict = row_dict\n",
    "    else:\n",
    "        file_dict = sum_dict\n",
    "    dire = path\n",
    "    for cat in news_category:\n",
    "        category = cat\n",
    "        files = os.listdir(dire + category)\n",
    "        file_dict[cat] = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMPGUVug95HE",
    "outputId": "aefeb0c6-05bc-4a31-9244-2b00fbd45639"
   },
   "outputs": [],
   "source": [
    "text = parsetext(row_doc, \"sport\", \"291.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkgkPijt95HO"
   },
   "outputs": [],
   "source": [
    "for name in row_dict[\"politics\"]:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gM75fs9g95Hc"
   },
   "outputs": [],
   "source": [
    "row_data = {}\n",
    "for cat in row_dict.keys():\n",
    "    cat_dict = {}\n",
    "    # row_data_frame[cat] = []\n",
    "    for i in range(0, len(row_dict[cat])):\n",
    "        filename = row_dict[cat][i]\n",
    "        path = row_doc + cat + \"/\" + filename\n",
    "        with open(path, \"rb\") as f:                \n",
    "            text = f.read()\n",
    "            cat_dict[filename[:3]] = text\n",
    "    row_data[cat] = cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MjPzSMPT95Hg"
   },
   "outputs": [],
   "source": [
    "sum_data = {}\n",
    "for cat in sum_dict.keys():\n",
    "    cat_dict = {}\n",
    "    # row_data_frame[cat] = []\n",
    "    for i in range(0, len(sum_dict[cat])):\n",
    "        filename = sum_dict[cat][i]\n",
    "        path = summary_doc + cat + \"/\" + filename\n",
    "        with open(path, \"rb\") as f:                \n",
    "            text = f.read()\n",
    "            cat_dict[filename[:3]] = text\n",
    "    sum_data[cat] = cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "du70GJ7o95H0",
    "outputId": "2f05e596-129f-489e-8fcd-e789f870fe9e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_business = pd.DataFrame.from_dict(row_data[\"business\"], orient=\"index\", columns=[\"row_article\"])\n",
    "news_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKbrhIYw95H8"
   },
   "outputs": [],
   "source": [
    "#  news_category = [\"business\", \"entertainment\", \"politics\", \"sport\", \"tech\"]\n",
    "news_entertainment = pd.DataFrame.from_dict(row_data[\"entertainment\"], orient=\"index\", columns=[\"row_article\"])\n",
    "news_politics = pd.DataFrame.from_dict(row_data[\"politics\"], orient=\"index\", columns=[\"row_article\"])\n",
    "news_sport = pd.DataFrame.from_dict(row_data[\"sport\"], orient=\"index\", columns=[\"row_article\"])\n",
    "news_tech = pd.DataFrame.from_dict(row_data[\"tech\"], orient=\"index\", columns=[\"row_article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KrSmXmON95IE"
   },
   "outputs": [],
   "source": [
    "# summary data\n",
    "summary_business = pd.DataFrame.from_dict(sum_data[\"business\"], orient=\"index\", columns=[\"summary\"])\n",
    "summary_entertainment = pd.DataFrame.from_dict(sum_data[\"entertainment\"], orient=\"index\", columns=[\"summary\"])\n",
    "summary_politics = pd.DataFrame.from_dict(sum_data[\"politics\"], orient=\"index\", columns=[\"summary\"])\n",
    "summary_sport = pd.DataFrame.from_dict(sum_data[\"sport\"], orient=\"index\", columns=[\"summary\"])\n",
    "summary_tech = pd.DataFrame.from_dict(sum_data[\"tech\"], orient=\"index\", columns=[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNL3-2xL95IJ",
    "outputId": "8dd40f58-2921-4c73-fd62-6b5b9e673169"
   },
   "outputs": [],
   "source": [
    "summary_business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aq407qkG95IO"
   },
   "outputs": [],
   "source": [
    "business = news_business.join(summary_business, how='inner')\n",
    "entertainment = news_entertainment.join(summary_entertainment, how='inner')\n",
    "politics = news_politics.join(summary_politics, how='inner')\n",
    "sport = news_sport.join(summary_sport, how='inner')\n",
    "tech = news_tech.join(summary_tech, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CKbjkn-r95IR"
   },
   "outputs": [],
   "source": [
    "business = news_business.join(summary_business, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fKfHtKbL95IW",
    "outputId": "11b33d28-b909-4924-8e97-3e978c473fe8"
   },
   "outputs": [],
   "source": [
    "business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_sUHqLUJ95Ib",
    "outputId": "7b492210-e0b1-4622-fcba-9c0f730ca3cd"
   },
   "outputs": [],
   "source": [
    "print(\"row\", len(business.iloc[0,0]))\n",
    "print(\"sum\", len(business.iloc[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VthiJz-h95Ij"
   },
   "outputs": [],
   "source": [
    "list_df = [business, entertainment, politics, sport, tech]\n",
    "length = 0\n",
    "for df in list_df:\n",
    "    length += len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hj44ZFO-95Iu",
    "outputId": "f5649126-2cf2-45ad-cc77-879985450f5b"
   },
   "outputs": [],
   "source": [
    "print(\"length of all data: \", length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vFtKW1DS95I2",
    "outputId": "f9e46aae-aa16-4415-8302-ddd47bd220ce"
   },
   "outputs": [],
   "source": [
    "bbc_df = pd.concat([business, entertainment, politics, sport, tech], ignore_index=True)\n",
    "len(bbc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xogCv95T95JF"
   },
   "source": [
    "## Step 2. Preprocessing Text Data\n",
    "1. Clean Text\n",
    "2. Tokenize\n",
    "3. Vocabrary\n",
    "4. Padding\n",
    "5. One-Hot Encoding\n",
    "6. Reshape to (MAX_LEN, One-Hot Encoding DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y2un_KkA95JU"
   },
   "source": [
    "### 2-1. Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxQY2wvq95JJ"
   },
   "outputs": [],
   "source": [
    "def cleantext(text):\n",
    "    text = str(text)\n",
    "    text=text.split()\n",
    "    words=[]\n",
    "    for t in text:\n",
    "        if t.isalpha():\n",
    "            words.append(t)\n",
    "    text=\" \".join(words)\n",
    "    text=text.lower()\n",
    "    text=re.sub(r\"what's\",\"what is \",text)\n",
    "    text=re.sub(r\"it's\",\"it is \",text)\n",
    "    text=re.sub(r\"\\'ve\",\" have \",text)\n",
    "    text=re.sub(r\"i'm\",\"i am \",text)\n",
    "    text=re.sub(r\"\\'re\",\" are \",text)\n",
    "    text=re.sub(r\"n't\",\" not \",text)\n",
    "    text=re.sub(r\"\\'d\",\" would \",text)\n",
    "    text=re.sub(r\"\\'s\",\"s\",text)\n",
    "    text=re.sub(r\"\\'ll\",\" will \",text)\n",
    "    text=re.sub(r\"can't\",\" cannot \",text)\n",
    "    text=re.sub(r\" e g \",\" eg \",text)\n",
    "    text=re.sub(r\"e-mail\",\"email\",text)\n",
    "    text=re.sub(r\"9\\\\/11\",\" 911 \",text)\n",
    "    text=re.sub(r\" u.s\",\" american \",text)\n",
    "    text=re.sub(r\" u.n\",\" united nations \",text)\n",
    "    text=re.sub(r\"\\n\",\" \",text)\n",
    "    text=re.sub(r\":\",\" \",text)\n",
    "    text=re.sub(r\"-\",\" \",text)\n",
    "    text=re.sub(r\"\\_\",\" \",text)\n",
    "    text=re.sub(r\"\\d+\",\" \",text)\n",
    "    text=re.sub(r\"[$#@%&*!~?%{}()]\",\" \",text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K7ovvCt495JL"
   },
   "outputs": [],
   "source": [
    "for col in bbc_df.columns:\n",
    "    bbc_df[col] = bbc_df[col].apply(lambda x: cleantext(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwbxBACO95JP",
    "outputId": "8b9cf24a-1714-47bf-944b-4aaa54ab78c4"
   },
   "outputs": [],
   "source": [
    "bbc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "JBPbkd8pIORs",
    "outputId": "51066e27-b9c1-467e-845a-b162e813ce2f"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YA9tvTPUIciB",
    "outputId": "1780794c-4748-49ba-8669-c75b875347d4"
   },
   "outputs": [],
   "source": [
    "len_list =[]\n",
    "for article in articles:\n",
    "    words = article.split()\n",
    "    length = len(words)\n",
    "    len_list.append(length)\n",
    "max(len_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jO14nm8JJPzZ"
   },
   "source": [
    "### 2-2. Tokenizer\n",
    "1. Tokenize and One-Hot : Tokenizer\n",
    "2. Vocabraly: article and summary 15000 words \n",
    "3. Padding: pad_sequences 1000 max_len\n",
    "4. Reshape: manual max_len * one-hot matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>continues rapid economy has expanded by a brea...</td>\n",
       "      <td>overall investment in fixed assets was still u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deccan seals deccan has ordered airbus planes ...</td>\n",
       "      <td>government has given its backing to cheaper an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>job growth continues in us created fewer jobs ...</td>\n",
       "      <td>creation was one of last main concerns for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owner buys rival for retail giant federated de...</td>\n",
       "      <td>retail giant federated department stores is to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>secures giant japan is to supply japan airline...</td>\n",
       "      <td>chose the after carefully considering both it ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         row_article  \\\n",
       "0  continues rapid economy has expanded by a brea...   \n",
       "1  deccan seals deccan has ordered airbus planes ...   \n",
       "2  job growth continues in us created fewer jobs ...   \n",
       "3  owner buys rival for retail giant federated de...   \n",
       "4  secures giant japan is to supply japan airline...   \n",
       "\n",
       "                                             summary  \n",
       "0  overall investment in fixed assets was still u...  \n",
       "1  government has given its backing to cheaper an...  \n",
       "2  creation was one of last main concerns for the...  \n",
       "3  retail giant federated department stores is to...  \n",
       "4  chose the after carefully considering both it ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_art_sum = pd.read_csv(\"cleaned_bbc_news.csv\")\n",
    "bbc_art_sum.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "bbc_art_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = list(bbc_art_sum.row_article)\n",
    "summaries = list(bbc_art_sum.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-1. Tokenize: text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "W9aALHY_YbUN",
    "outputId": "b228cf03-c36b-413a-d3c8-c9cb6fff1b36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23914"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "VOCAB_SIZE = 14999\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(articles)\n",
    "article_sequences = tokenizer.texts_to_sequences(articles)\n",
    "art_word_index = tokenizer.word_index\n",
    "len(art_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1411, 2338, 248, 16, 3994, 22, 5, 6483, 165, 1359, 50, 966, 4, 120, 967, 176, 118, 505, 38, 2339]\n",
      "[5211, 8881, 5211, 16, 2233, 3001, 3441, 6, 5, 217, 18, 60, 1270, 7874, 6, 1, 827, 5211, 11, 108]\n",
      "[478, 196, 1411, 6, 54, 736, 2283, 498, 50, 164, 6, 24, 349, 17, 9, 1, 3322, 6, 5213, 11]\n"
     ]
    }
   ],
   "source": [
    "print(article_sequences[0][:20])\n",
    "print(article_sequences[1][:20])\n",
    "print(article_sequences[2][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-2. Vocabraly: article and summary 15000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_word_index_1500 = {}\n",
    "counter = 0\n",
    "for word in art_word_index.keys():\n",
    "    if art_word_index[word] == 0:\n",
    "        print(\"found 0!\")\n",
    "        break\n",
    "    if art_word_index[word] > VOCAB_SIZE:\n",
    "        continue\n",
    "    else:\n",
    "        art_word_index_1500[word] = art_word_index[word]\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23929"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(summaries)\n",
    "summary_sequences = tokenizer.texts_to_sequences(summaries)\n",
    "sum_word_index = tokenizer.word_index\n",
    "len(sum_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_word_index_1500 = {}\n",
    "counter = 0\n",
    "for word in sum_word_index.keys():\n",
    "    if sum_word_index[word] == 0:\n",
    "        print(\"found 0!\")\n",
    "        break\n",
    "    if sum_word_index[word] > VOCAB_SIZE:\n",
    "        continue\n",
    "    else:\n",
    "        sum_word_index_1500[word] = sum_word_index[word]\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-3. Padding: pad_sequences 1000 max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_LEN = 1000\n",
    "pad_art_sequences = pad_sequences(article_sequences, maxlen=MAX_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(article_sequences[1]), len(pad_art_sequences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_sum_sequences = pad_sequences(summary_sequences, maxlen=MAX_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(summary_sequences[1]), len(pad_sum_sequences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_art_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1411, 2338,  248, ...,    0,    0,    0],\n",
       "       [5211, 8881, 5211, ...,    0,    0,    0],\n",
       "       [ 478,  196, 1411, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 421, 1337, 2012, ...,    0,    0,    0],\n",
       "       [2164,  267, 1109, ...,    0,    0,    0],\n",
       "       [   7,  284,    8, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_art_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-4. Reshape: manual max_len * one-hot matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使わない\n",
    "encoder_inputs = np.zeros((2225, 1000), dtype='float32')\n",
    "encoder_inputs.shape\n",
    "\n",
    "decoder_inputs = np.zeros((2225, 1000), dtype='float32')\n",
    "decoder_inputs.shape\n",
    "\n",
    "for i, seqs in enumerate(pad_art_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        encoder_inputs[i, j] = seq\n",
    "        \n",
    "for i, seqs in enumerate(pad_sum_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        decoder_inputs[i, j] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 1000, 15000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs = np.zeros((2225, 1000, 15000), dtype='float32')\n",
    "decoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, seqs in enumerate(pad_sum_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        decoder_outputs[i, j, seq] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225, 1000, 15000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-5. Pre-trained word2vec and word2vec Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sokvMj0Xfnjw",
    "outputId": "3ef40349-e3e7-4f25-d263-7d316d21f829"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B.200d.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdx3r2rvZAwN"
   },
   "outputs": [],
   "source": [
    "def embedding_matrix_creater(embedding_dimention, word_index):\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dimention))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "          # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VB6UmXeqWleO",
    "outputId": "59e76cc0-91a2-454b-a61e-f7cb1b2cf59a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 200)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_embedding_matrix = embedding_matrix_creater(200, word_index=art_word_index_1500)\n",
    "art_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1KgrdRFvb7A1",
    "outputId": "e01036f5-476b-46eb-bec7-1ad263ba9dd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 200)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_embedding_matrix = embedding_matrix_creater(200, word_index=sum_word_index_1500)\n",
    "sum_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vuawT3rXUIBY"
   },
   "outputs": [],
   "source": [
    "encoder_embedding_layer = Embedding(input_dim = 15000, \n",
    "                                    output_dim = 200,\n",
    "                                    input_length = MAX_LEN,\n",
    "                                    weights = [art_embedding_matrix],\n",
    "                                    trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wf3EzUZcIccZ"
   },
   "outputs": [],
   "source": [
    "decoder_embedding_layer = Embedding(input_dim = 15000, \n",
    "                                    output_dim = 200,\n",
    "                                    input_length = MAX_LEN,\n",
    "                                    weights = [sum_embedding_matrix],\n",
    "                                    trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J5acWwCxIcZz",
    "outputId": "a92cd279-b2de-4110-fd1d-35e13e90c099"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 200)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AB663AaY0PKH"
   },
   "source": [
    "## Step 3. Building Encoder-Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-kZT0pQRqRl"
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pydot\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras import backend as k\n",
    "k.set_learning_phase(1)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import initializers\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,LSTM,Dropout,Input,Activation,Add,concatenate, Embedding, RepeatVector\n",
    "from keras.layers.advanced_activations import LeakyReLU,PReLU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psWPxabWIcWz"
   },
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "\n",
    "MAX_LEN = 1000\n",
    "VOCAB_SIZE =15000\n",
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_UNITS = 200\n",
    "VOCAB_SIZE = VOCAB_SIZE + 1\n",
    "\n",
    "LEARNING_RATE = 0.002\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1. Simple LSTM Encoder-Decoder-seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pGjWMUG3IcT_"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple LSTM Encoder-Decoder-seq2seq\n",
    "\"\"\"\n",
    "# encoder\n",
    "encoder_inputs = Input(shape=(MAX_LEN, ), dtype='int32',)\n",
    "encoder_embedding = encoder_embedding_layer(encoder_inputs)\n",
    "encoder_LSTM = LSTM(HIDDEN_UNITS)(encoder_embedding)\n",
    "# decoder\n",
    "decoder_inputs = Input(shape=(MAX_LEN, ))\n",
    "decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
    "decoder_LSTM = LSTM(200)(decoder_embedding)\n",
    "# merge\n",
    "merge_layer = concatenate([encoder_LSTM, decoder_LSTM])\n",
    "decoder_outputs = Dense(units=VOCAB_SIZE+1, activation=\"softmax\")(merge_layer) # SUM_VOCAB_SIZE, sum_embedding_matrix.shape[1]\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JHw0flwp4uW2"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2. Bidirectional LSTM Encoder-Decoder-seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bidirectional LSTM: Others Inspired Encoder-Decoder-seq2seq\n",
    "\"\"\"\n",
    "encoder_inputs = Input(shape=(MAX_LEN,))\n",
    "encoder_embedding = encoder_embedding_layer(encoder_inputs)\n",
    "encoder_LSTM = LSTM(HIDDEN_UNITS, return_state=True)\n",
    "encoder_LSTM_R = LSTM(HIDDEN_UNITS, return_state=True, go_backwards=True)\n",
    "encoder_outputs_R, state_h_R, state_c_R = encoder_LSTM_R(encoder_embedding)\n",
    "encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n",
    "\n",
    "final_h = Add()([state_h, state_h_R])\n",
    "final_c = Add()([state_c, state_c_R])\n",
    "encoder_states = [final_h, final_c]\n",
    "\n",
    "\"\"\"\n",
    "decoder\n",
    "\"\"\"\n",
    "decoder_inputs = Input(shape=(MAX_LEN,))\n",
    "decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
    "decoder_LSTM = LSTM(HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_LSTM(decoder_embedding, initial_state=encoder_states) \n",
    "decoder_dense = Dense(VOCAB_SIZE, activation='linear')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model= Model(inputs=[encoder_inputs,decoder_inputs], outputs=decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3. Chatbot Inspired Encoder-Decoder-seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Chatbot Inspired Encoder-Decoder-seq2seq\n",
    "\"\"\"\n",
    "encoder_inputs = Input(shape=(MAX_LEN, ), dtype='int32',)\n",
    "encoder_embedding = encoder_embedding_layer(encoder_inputs)\n",
    "encoder_LSTM = LSTM(HIDDEN_UNITS, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_LSTM(encoder_embedding)\n",
    "\n",
    "decoder_inputs = Input(shape=(MAX_LEN, ), dtype='int32',)\n",
    "decoder_embedding = decoder_embedding_layer(decoder_inputs)\n",
    "decoder_LSTM = LSTM(HIDDEN_UNITS, return_state=True, return_sequences=True)\n",
    "decoder_outputs, _, _ = decoder_LSTM(decoder_embedding, initial_state=[state_h, state_c])\n",
    "\n",
    "# dense_layer = Dense(VOCAB_SIZE, activation='softmax')\n",
    "outputs = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))(decoder_outputs)\n",
    "model = Model([encoder_inputs, decoder_inputs], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = RMSprop(lr=0.01, clipnorm=1.)\n",
    "model.compile(loss='mse', optimizer=rmsprop, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1000, 200)    3000000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 200), (None, 320800      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 200), (None, 320800      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1000, 200)    3000000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 200)          0           lstm_1[0][1]                     \n",
      "                                                                 lstm_2[0][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 200)          0           lstm_1[0][2]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 1000, 200),  320800      embedding_2[0][0]                \n",
      "                                                                 add_1[0][0]                      \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1000, 15001)  3015201     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 9,977,601\n",
      "Trainable params: 3,977,601\n",
      "Non-trainable params: 6,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model 2\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Training your model and Validate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_samples = len(pad_sum_sequences)\n",
    "decoder_output_data = np.zeros((num_samples, MAX_LEN, VOCAB_SIZE), dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputの３Dテンソル\n",
    "for i, seqs in enumerate(pad_sum_sequences):\n",
    "    for j, seq in enumerate(seqs):\n",
    "        if j > 0:\n",
    "            decoder_output_data[i][j][seq] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EFxSEKvfIoGf"
   },
   "outputs": [],
   "source": [
    "art_train, art_test, sum_train, sum_test = train_test_split(pad_art_sequences, pad_sum_sequences, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9hn_1hm-JCa2",
    "outputId": "95c79153-06ec-4b2d-b25e-6f34c933ae44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num = art_train.shape[0]\n",
    "train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = decoder_output_data[:train_num]\n",
    "target_test = decoder_output_data[train_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1780 samples, validate on 445 samples\n",
      "Epoch 1/5\n",
      "  32/1780 [..............................] - ETA: 8:49:51 - loss: 1.6950e-04 - acc: 0.4530"
     ]
    }
   ],
   "source": [
    "history = model.fit([art_train, sum_train], \n",
    "                     target_train, \n",
    "                     epochs=EPOCHS, \n",
    "                     batch_size=BATCH_SIZE,\n",
    "                     validation_data=([art_test, sum_test], target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正確性の可視化\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の可視化\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "with open('text_summary.json',\"w\").write(model.to_json())\n",
    "\n",
    "# 重みの読み込み\n",
    "model.load_weights('text_summary.h5')\n",
    "print(\"Saved Model!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pm-V-4MiIos7"
   },
   "source": [
    "## Step 5. Inference phase and Generate summary from fuyure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_model(encoder_inputs, encoder_states, HIDDEN_UNITS):\n",
    "    \n",
    "    # encoder\n",
    "    encoder_model_inf = Model(encoder_inputs, encoder_states)\n",
    "    # decoder\n",
    "    decoder_input_state_H = Input(shape=(HIDDEN_UNITS,))\n",
    "    decoder_input_state_C = Input(shape=(HIDDEN_UNITS,)) \n",
    "    decoder_state_inputs = [decoder_input_state_H, decoder_input_state_C]\n",
    "    # merge\n",
    "    decoder_outputs, decoder_state_h, decoder_state_c = decoder_LSTM(decoder_inputs, initial_state=decoder_state_inputs)\n",
    "    decoder_states = [decoder_state_h, decoder_state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    # decoder完成\n",
    "    decoder_model_inf = Model([decoder_inputs]+decoder_state_inputs,\n",
    "                               [decoder_outputs]+decoder_states)\n",
    "    \n",
    "    return decoder_model_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = inference_model(encoder_inputs, encoder_states, HIDDEN_UNITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Text_Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "PAD = 8399 \n",
    "\n",
    "def Automatic_Summarizer(text, PAD=8399):\n",
    "    # トークン化\n",
    "    tokens = text_to_word_sequence(text)\n",
    "    # シーケンス化\n",
    "    sequences = []\n",
    "    for token in tokens:\n",
    "        if token in word2idx.keys():\n",
    "            idx = word2idx[token]\n",
    "            sequences.append(idx)\n",
    "        else:\n",
    "            continue\n",
    "    # パディング\n",
    "    encoder_input_data = pad_sequences(sequences, value=PAD) \n",
    "    decoder_output_data =np.reshape(encoder_input_data, (1, MAX_LEN, VOCAB_SIZE)\n",
    "    \n",
    "    init_state_val = encoder.predict(article)\n",
    "    target_seq = np.zeros((1, 1, emb_size_all))\n",
    "    \n",
    "    # NNにフィード\n",
    "    summarised_words = []\n",
    "    stop_pred = False\n",
    "    while not stop_pred:\n",
    "        decoder_out,decoder_h,decoder_c= decoder.predict(x=[padded_sequences]+init_state_val)\n",
    "        generated_summary.append(decoder_out)\n",
    "        init_state_val= [decoder_h,decoder_c]\n",
    "\n",
    "        target_seq=np.reshape(decoder_out,(1,1,emb_size_all))\n",
    "        if len(generated_summary)== de_shape[0]:\n",
    "            stop_pred=True\n",
    "            break\n",
    "    \n",
    "    summarised_text = \" \".join(summarised_words)\n",
    "        \n",
    "    return summarised_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"___generate summary vectors___\"\"\"\n",
    "\n",
    "def summarize(article):\n",
    "    stop_pred = False\n",
    "    article =  np.reshape(article,(1,en_shape[0],en_shape[1]))\n",
    "    \n",
    "    #get initial h and c values from encoder\n",
    "    init_state_val = encoder.predict(article)\n",
    "    target_seq = np.zeros((1,1,emb_size_all))\n",
    "    \n",
    "    generated_summary=[]\n",
    "    while not stop_pred:\n",
    "        decoder_out,decoder_h,decoder_c= decoder.predict(x=[target_seq]+init_state_val)\n",
    "        generated_summary.append(decoder_out)\n",
    "        init_state_val= [decoder_h,decoder_c]\n",
    "        #get most similar word and put in line to be input in next timestep\n",
    "        #target_seq=np.reshape(model.wv[getWord(decoder_out)[0]],(1,1,emb_size_all))\n",
    "        target_seq=np.reshape(decoder_out,(1,1,emb_size_all))\n",
    "        if len(generated_summary)== de_shape[0]:\n",
    "            stop_pred=True\n",
    "            break\n",
    "    return generated_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model,encoder,decoder = encoder_decoder(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trained_model, encoder,decoder\n",
    "getWord(collect_pred[23])\n",
    "model.wv.most_similar(np.zeros((1,emb_size_all)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "input_matrix.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
